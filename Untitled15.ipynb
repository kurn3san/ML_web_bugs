{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kurn3san/ML_web_bugs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwWIkb8bHutD",
        "outputId": "9f47463e-9774-42af-87f0-9926e04524ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML_web_bugs'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 8 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (8/8), 7.60 MiB | 5.68 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOw8zLTHIu4m",
        "outputId": "3b30c99d-0ab3-4456-9f90-83c1cba8ab31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.5-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt4o=\"gpt-4o\"\n",
        "gpt3=\"gpt-3.5-turbo\"\n",
        "gpt4=\"gpt-4\"\n",
        "gpt4turbo=\"gpt-4-turbo\"\n",
        "gpts=[gpt3,gpt4o,gpt4,gpt4turbo]\n",
        "from openai import OpenAI\n",
        "api_key = ''\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "ysnG8xKeIsnG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import openai as ai\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import precision_score"
      ],
      "metadata": {
        "id": "C8-mEYGYHCfS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_gpt_a_coding_question(model_name:str,question:str):\n",
        "    completion=client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[\n",
        "            {\"role\":\"system\",\n",
        "                  \"content\": ''' You are an assistant who's specialized in solving ML problems. You analyze my questions, see what are the key topics or key words related to the question and the answer of my question. and then respond with a elaborate reasoning and step by step explaination of your solution approach. then you deliver me the python code. You may select the best three options, if you find different solution approaches to my problem. Beautify the content of the response object in markdown, so when I take the content of response.message.content into a string and paste it in the text section in a jupyter notebook, I see html view '''},\n",
        "            {\"role\":\"user\",\n",
        "                  \"content\":question}\n",
        "        ]\n",
        "    )\n",
        "    resp=completion.choices[0]\n",
        "    return resp.message.content\n",
        "\n",
        "def ask_gpt_a_ML_problem(model_name:str,ml_problem:str):\n",
        "    completion=client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[\n",
        "            {\"role\":\"system\",\n",
        "                  \"content\": ''' You are an assistant who's specialized in solving ML problems. You analyze my ML-problem, see what are the key topics or key words related to the question and the answer of my question. give me the best ML algorithms that are optimal or near optimal for solving my probelm, and you'll explain your decision. You respond with a elaborate reasoning and step by step explaination of your solution approach. Then you deliver me the python code. You may select the best three options, if you find different solution approaches to my problem. Beautify the content of the response object in markdown, so when I take the content of response.message.content into a string and paste it in the text section in a jupyter notebook, I see html view '''},\n",
        "            {\"role\":\"user\",\n",
        "                  \"content\":ml_problem}\n",
        "        ]\n",
        "    )\n",
        "    resp=completion.choices[0]\n",
        "    return resp.message.content"
      ],
      "metadata": {
        "id": "JTJxaC38IkJr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training data\n",
        "train_df = pd.read_csv('/content/ML_web_bugs/bugs-train.csv')\n"
      ],
      "metadata": {
        "id": "YKz5AQ_FHGSW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['severity']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8172za436hx4",
        "outputId": "64e74404-d52a-4666-c0d4-77be76a435ba"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           normal\n",
              "1         critical\n",
              "2            major\n",
              "3           normal\n",
              "4         critical\n",
              "            ...   \n",
              "159993      normal\n",
              "159994      normal\n",
              "159995    critical\n",
              "159996    critical\n",
              "159997      normal\n",
              "Name: severity, Length: 159998, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure stopwords are downloaded\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize stemmer and stopwords\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPuUBM0IHPsl",
        "outputId": "f9978494-7c62-4fdb-97e7-f9590cdbcfe2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Clean text data\n",
        "def preprocess_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove non-Latin characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize and remove stopwords\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    # Apply stemming\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "    return ' '.join(words)\n"
      ],
      "metadata": {
        "id": "fsTU53TaHR3Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['summary'] = train_df['summary'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "YruYM14HHsTC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['severity']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9M-Kj3W6Zk6",
        "outputId": "96371bae-197d-4b63-a761-40982669b989"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         5\n",
              "1         1\n",
              "2         3\n",
              "3         5\n",
              "4         1\n",
              "         ..\n",
              "159993    5\n",
              "159994    5\n",
              "159995    1\n",
              "159996    1\n",
              "159997    5\n",
              "Name: severity, Length: 159998, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode severity labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_y = label_encoder.fit_transform(train_df['severity'])\n"
      ],
      "metadata": {
        "id": "Vu0lNDCL_7GB"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNHzZgPc__e7",
        "outputId": "e8dea54a-2acd-4aef-d0fb-68ac3b3bfc66"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['blocker', 'critical', 'enhancement', 'major', 'minor', 'normal',\n",
              "       'trivial'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode severity labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['severity'] = label_encoder.fit_transform(train_df['severity'])\n",
        "\n",
        "# Convert text data into TF-IDF features\n",
        "vectorizer = TfidfVectorizer()  # Reduced from 5000 to 2000\n",
        "X = vectorizer.fit_transform(train_df['summary'])\n",
        "y = train_df['severity']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HVQCp4k4HsQk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize and fit the Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n"
      ],
      "metadata": {
        "id": "44UqhlbKJtZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_modelim=SVC(kernel='linear')\n",
        "svm_modelim.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2B5A7v7eJtW9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "ffd1fbec-d7b9-4c05-f508-55fc67729f41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(kernel='linear')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm_modelim.predict(X_val)\n",
        "macro_precision = precision_score(y_val, y_pred, average='macro')\n",
        "\n",
        "print(f\"Macro Precision: {macro_precision}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xC3DdTHUDrp",
        "outputId": "a475be9b-a858-4d9a-99b2-f75cb173e0e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro Precision: 0.7997134083215821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=pd.read_csv(\"/content/ML_web_bugs/bugs-test.csv\")['summary']"
      ],
      "metadata": {
        "id": "1rZMNn8mxZjL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data= test_data.apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "S9V5g4lg02c-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_test_data = vectorizer.transform(test_data)"
      ],
      "metadata": {
        "id": "i1kultK3yyeZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_prediction=svm_modelim.predict(vectorized_test_data)"
      ],
      "metadata": {
        "id": "zVbW8eX0ym2L"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "shfxp9sU5q7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sud0GEqk4yl1",
        "outputId": "716da93a-111d-4402-f990-1401790e96a2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, ..., 1, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.classes_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpIAXpwv6Rbd",
        "outputId": "8e37435a-3eeb-4ec1-fcd8-524649b01ada"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_prediction_decoded = label_encoder.inverse_transform(y_test_prediction)\n"
      ],
      "metadata": {
        "id": "Vp5MMVoY5rVa"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_prediction_decoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI7wY4nbAGOk",
        "outputId": "4d99a21b-4c73-41a7-c5da-0bc41e871960"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['normal', 'normal', 'normal', ..., 'critical', 'critical',\n",
              "       'normal'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame({'summary': test_data,'severity': y_test_prediction_decoded})"
      ],
      "metadata": {
        "id": "NxraknMgAkrZ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('/content/ML_web_bugs/bugs-test-output.csv')"
      ],
      "metadata": {
        "id": "LY1111tW5Jdw"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('/content/ML_web_bugs/bugs-test-output2.csv')"
      ],
      "metadata": {
        "id": "guFPHkpnA6JY"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8mfJI8lj5Y7P",
        "outputId": "7d6d5cac-9fef-4c92-de9c-ccd77a6f0d83"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 summary  severity\n",
              "0      firefox claim default browser updatealtern con...         5\n",
              "1      background html bodi element appli correctli i...         5\n",
              "2      mous input break use windowshowmodaldialog ful...         5\n",
              "3       build failur next freetyp versioncurr git master         5\n",
              "4            html element treat root insid foreignobject         5\n",
              "...                                                  ...       ...\n",
              "86089           crash bool isabouttobefinalizedinternalt         1\n",
              "86090  potenti crash graphrat greater khz webrtcaudio...         1\n",
              "86091  crash name omit decltyp jsdispatchtracekindtypedt         1\n",
              "86092           crash xuldllxfa xuldllxcff mozgluedllxcd         1\n",
              "86093       symbol clangrtasandynamicxdl taskclust build         5\n",
              "\n",
              "[86094 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c692dfc-4b6e-4bf8-a4df-896df6c03859\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>firefox claim default browser updatealtern con...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>background html bodi element appli correctli i...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mous input break use windowshowmodaldialog ful...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>build failur next freetyp versioncurr git master</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>html element treat root insid foreignobject</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86089</th>\n",
              "      <td>crash bool isabouttobefinalizedinternalt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86090</th>\n",
              "      <td>potenti crash graphrat greater khz webrtcaudio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86091</th>\n",
              "      <td>crash name omit decltyp jsdispatchtracekindtypedt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86092</th>\n",
              "      <td>crash xuldllxfa xuldllxcff mozgluedllxcd</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86093</th>\n",
              "      <td>symbol clangrtasandynamicxdl taskclust build</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86094 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c692dfc-4b6e-4bf8-a4df-896df6c03859')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c692dfc-4b6e-4bf8-a4df-896df6c03859 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c692dfc-4b6e-4bf8-a4df-896df6c03859');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-310eb10d-199e-437b-a46e-0d0f7d6f2042\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-310eb10d-199e-437b-a46e-0d0f7d6f2042')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-310eb10d-199e-437b-a46e-0d0f7d6f2042 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7952e86a-16db-4a58-99ba-70c83c10ed87\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7952e86a-16db-4a58-99ba-70c83c10ed87 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 86094,\n  \"fields\": [\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 82819,\n        \"samples\": [\n          \"mse receiv unexpect error event\",\n          \"streamlin macosfontentryhasfontt\",\n          \"whatsapp web display wrongli page set block load resourc dataimag imgsrc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"severity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messa=ask_gpt_a_ML_problem(gpt4turbo,'''\n",
        "\n",
        "analyse this code and tell me why the error happened!\n",
        "\n",
        "train_df = pd.read_csv('/content/ML_web_bugs/bugs-train.csv')\n",
        "# Encode severity labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['severity'] = label_encoder.fit_transform(train_df['severity'])\n",
        "\n",
        "# Convert text data into TF-IDF features\n",
        "vectorizer = TfidfVectorizer()  # Reduced from 5000 to 2000\n",
        "X = vectorizer.fit_transform(train_df['summary'])\n",
        "y = train_df['severity']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_modelim=SVC(kernel='linear')\n",
        "svm_modelim.fit(X_train, y_train)\n",
        "y_pred = svm_modelim.predict(X_val)\n",
        "macro_precision = precision_score(y_val, y_pred, average='macro')\n",
        "\n",
        "print(f\"Macro Precision: {macro_precision}\")\n",
        "\n",
        "test_data=pd.read_csv(\"/content/ML_web_bugs/bugs-test.csv\")['summary']\n",
        "test_data= test_data.apply(preprocess_text)\n",
        "\n",
        "vectorized_test_data = vectorizer.fit_transform(test_data)\n",
        "\n",
        "y_test_prediction=svm_modelim.predict(vectorized_test_data)\n",
        "---------------------------------------------------------------------------\n",
        "ValueError                                Traceback (most recent call last)\n",
        "<ipython-input-21-df38bf50bbf5> in <cell line: 1>()\n",
        "----> 1 y_test_prediction=svm_modelim.predict(vectorized_test_data)\n",
        "\n",
        "4 frames\n",
        "/usr/local/lib/python3.10/dist-packages/sklearn/base.py in _check_n_features(self, X, reset)\n",
        "    387\n",
        "    388         if n_features != self.n_features_in_:\n",
        "--> 389             raise ValueError(\n",
        "    390                 f\"X has {n_features} features, but {self.__class__.__name__} \"\n",
        "    391                 f\"is expecting {self.n_features_in_} features as input.\"\n",
        "\n",
        "ValueError: X has 54399 features, but SVC is expecting 87847 features as input.''')\n"
      ],
      "metadata": {
        "id": "3m30KwyVymzr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(messa)"
      ],
      "metadata": {
        "id": "lIHcfjtdymxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hey\")"
      ],
      "metadata": {
        "id": "RTmAgq4QlGFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Analysis & Error Explanation\n",
        "\n",
        "The error indicates a mismatch in the number of features expected by the model (`SVC` trained model) versus the number of features present in the new test data. Here's a succinct step-by-step explanation to understand why this error happened:\n",
        "\n",
        "### 1. Understanding the Feature Space\n",
        "\n",
        "The SVM model is trained using the `TfidfVectorizer` transformation of the `train_df['summary']` data, where each feature corresponds to a different term's TF-IDF score. This vectorization process extracts 87,847 unique terms/features.\n",
        "\n",
        "### 2. Application on Test Data\n",
        "\n",
        "When processing the test data:\n",
        "\n",
        "- You called `vectorizer.fit_transform(test_data)`, which not only vectorizes the `test_data` but also fits the vectorizer model to it. This naturally recalibrated the vectorizer based on only the terms found in `test_data`. Thus, generating a different set of features (54,399 unique terms/features in this instance) than those for which the model was initially trained.\n",
        "\n",
        "### 3. Model Prediction\n",
        "\n",
        "When the `svm_modelim` is used to predict the labels for `test_data`, it expects the test data's feature-set to match the training data's feature-set (87,847 features). Given the feature mismatch, Python raises the `ValueError`.\n",
        "\n",
        "## Solution Approach\n",
        "\n",
        "To avoid this error, you should ensure that the same features (terms) used in training are used for making predictions on any new (or test) data. You can achieve this by using `transform()` instead of `fit_transform()` on the test data.\n",
        "\n",
        "Here's the revised portion of the code:\n",
        "\n",
        "```python\n",
        "# Import necessary libraries\n",
        "import pandas as even_pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load the training data\n",
        "train_data = pd.read_csv('/content/ML_web_bugs/bugs-train.csv')\n",
        "\n",
        "# Encode severity labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['severity'] = label_encoder.fit_transform(train_data['severity'])\n",
        "\n",
        "# Convert text data into TF-IDF features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(train_data['summary'])\n",
        "y = train_data['severity']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_testimage_data_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a linear SVM model\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction and evaluation on validation set\n",
        "y_pred = svm_model.predict(X_val)\n",
        "val_macro_precision = precision_score(y_val, y_pred, average='macro')\n",
        "print(f\"Validation Macro Precision: {val_macro_precision}\")\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_data = pd.read_csv(\"/content/ML_web_bugs/bugs-test.csv\")['summary']\n",
        "\n",
        "# Convert test data text into TF-IDF features using the fitted vectorizer\n",
        "vectorized_test_data = vectorizer.transform(test_data)\n",
        "\n",
        "# Prediction on test data\n",
        "y_test_prediction = svm_model.predict(vectorized_test_data)\n",
        "\n",
        "# Output predictions\n",
        "print(y_test_prediction)\n",
        "```\n",
        "\n",
        "### Key Modifications:\n",
        "- Used `vectorizer.transform(test_data)` instead of `vectorizer.fit_transform(test_data)` for transforming test data.\n",
        "- Replaced `vectorizer.fit_transform` with `vectorizer.fit` on training data and `vectorizer.transform` on any subsequent data.\n",
        "\n",
        "This modification ensures consistency in the feature space across training and testing datasets, thereby avoiding the reported error."
      ],
      "metadata": {
        "id": "LveADqiR2D0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model\n",
        "y_pred = best_model.predict(X_val)\n",
        "print(\"Model: Logistic Regression with Hyperparameter Tuning\")\n",
        "print(classification_report(y_val, y_pred, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "ADKW8FxOUVm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PgqGqkSgUVkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0mxKQ3sUVen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('bugs-test.csv')\n",
        "test_df['summary'] = test_df['summary'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "pzj8CUugUDn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNvdQZ4OUISI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "94nyWz5BUIP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PihPMF2mUIM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "grid_search = GridSearchCV(\n",
        "    svm_modelim,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "gH07JkauKtPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nwf2I77UKtKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQWHfSq9G-XS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Get the best model\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model\n",
        "y_pred = best_model.predict(X_val)\n",
        "print(\"Model: Logistic Regression with Hyperparameter Tuning\")\n",
        "print(classification_report(y_val, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Load and preprocess the test data\n",
        "test_df = pd.read_csv('bugs-test.csv')\n",
        "test_df['summary'] = test_df['summary'].apply(preprocess_text)\n",
        "\n",
        "# Convert test data into TF-IDF features\n",
        "X_test = vectorizer.transform(test_df['summary'])\n",
        "\n",
        "# Predict using the best model\n",
        "test_df['severity'] = label_encoder.inverse_transform(best_model.predict(X_test))\n",
        "\n",
        "# Save the submission file\n",
        "submission4 = test_df[['bug_id', 'severity']]\n",
        "submission4.to_csv('submission4.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = ask_gpt_a_ML_problem(gpt4turbo,\n",
        "                               ''' what does this code do?\n",
        "                               vectorizer = TfidfVectorizer(max_features=2000)  # Reduced from 5000 to 2000\n",
        "\n",
        "                               '''\n",
        "                               )"
      ],
      "metadata": {
        "id": "l7JQYL2BIkxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(message)"
      ],
      "metadata": {
        "id": "BbDDwcvZI4Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Code\n",
        "\n",
        "The provided line of code initializes an instance of the `TfidfVectorizer` class from the scikit-learn library in Python. This instance is specifically configured to transform text data into a format suitable for machine learning models by using the TF-IDF (Term Frequency-Inverse Document Frequency) method. Below is a detailed step-by-step explanation of the purpose and functionalities of this code snippet:\n",
        "\n",
        "1. **Importing TfidfVectorizer**: Before you can use the `TfidfVectorizer`, you need to ensure that it is imported from the `sklearn.feature_extraction.text` module. The `TfidfVectorizer` is designed to convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "\n",
        "2. **Creating an Instance of TfidfVectorizer**:\n",
        "   - `vectorizer = TfidfVectorizer(max_features=2000)`\n",
        "     - `max_features=2000`: This parameter limits the number of most relevant features (unique terms) to be included in the TF-IDF matrix. The value has been reduced from 5000 to 2000, meaning the model now considers only the top 2000 terms ordered by term frequency across the corpus. This reduction helps in managing memory and can improve the performance of machine learning algorithms by removing less significant features.\n",
        "\n",
        "3. **Functionality**:\n",
        "   - When you call the `fit_transform()` method on `vectorizer` with a list of text data as input, it performs two main steps:\n",
        "     1. `fit`: Learns the vocabulary and idf (inverse document frequency) of the training data.\n",
        "     2. `transform`: Transforms the text data to a sparse matrix of TF-IDF vectors where each row corresponds to a document and each column represents a term from the learned vocabulary.\n",
        "   - The resulting sparse matrix can then be used as input to various machine learning models for tasks like classification, clustering, or similarity searches.\n",
        "\n",
        "By using TF-IDF, this vectorization method weighs the terms taking into account not only their frequency in a single document but also their frequency across all documents in the dataset. Terms that occur frequently in a document but rarely in others receive a high rating, making them more significant.\n",
        "\n",
        "### Python Code Example\n",
        "\n",
        "Here’s a simple example demonstrating how to use `TfidfVectorizer` in a full Python script for better understanding:\n",
        "\n",
        "```python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Sample text data\n",
        "documents = [\"machine learning is fun\", \"Python is great for machine learning\", \"Machine learning is vast\"]\n",
        "\n",
        "# Initialize a TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=2000)\n",
        "\n",
        "# Fit and transform the documents\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Print the shape of the tfidf matrix\n",
        "print(tfidf_matrix.shape)\n",
        "\n",
        "# Display the TF-IDF features names\n",
        "print(vectorizer.get_feature_names_out())\n",
        "```\n",
        "\n",
        "This script will show you the dimensions of the TF-IDF matrix (number of documents x number of terms) and print the terms that have been considered as features.\n"
      ],
      "metadata": {
        "id": "Vl5b2aZsI-9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h4gsirLKI7ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message3=ask_gpt_a_ML_problem(gpt4turbo\n",
        "                          ,\n",
        "                              '''\n",
        "                              what does this code do?\n",
        "                              param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],  # 'elasticnet' and 'none' are supported from sklearn 0.24\n",
        "    'solver': ['liblinear', 'saga']\n",
        "    param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],  # 'elasticnet' and 'none' are supported from sklearn 0.24\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    log_reg,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the grid search model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "}''')"
      ],
      "metadata": {
        "id": "og6dIGQdI6WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(message3)"
      ],
      "metadata": {
        "id": "WoHVuBt7J_pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet you provided is setting up a parameter grid search for tuning a logistic regression model using `GridSearchCV` from the `scikit-learn` library. Below is a detailed explanation of each part of the code:\n",
        "\n",
        "### Breakdown of the Code\n",
        "\n",
        "1. **Parameter Grid (param_grid):**\n",
        "   This is a dictionary containing the parameters that will be tested during the grid search. The parameters included are:\n",
        "   - `'C'`: This is the inverse of regularization strength. Smaller values specify stronger regularization. A list of values `[0.01, 0.1, 1, 10, 100]` is provided to see which value leads to the best performing model.\n",
        "   - `'penalty'`: This specifies the norm used in the penalization. The options include `'l1'` and `'l2'`. The `'l1'` penalty corresponds to Lasso regularization which can lead to sparse models, whereas `'l2'` corresponds to Ridge regularization.\n",
        "   - `'solver'`: These are the algorithms to use in the optimization problem. `'liblinear'` is a good choice for smaller datasets and supports both `'l1'` and `'l2'` penalties. `'saga'` is a variant that also supports non-smooth penalty functions like `'l1'` and is generally faster for large datasets.\n",
        "\n",
        "2. **Initialization of GridSearchCV:**\n",
        "   - The `GridSearchCV` function is initialized with several arguments:\n",
        "     - The model `log_reg` which appears to be an instance of a logistic regression model (though its definition isn't shown in the snippet).\n",
        "     - `param_grid` which includes the dictionary of parameters to test.\n",
        "     - `cv=3` signifies that 3-fold cross-validation will be used. This means the training data is divided into 3 parts, where each part gets to be the test set once with the rest serving as the training data, ensuring that the model's performance is robust and less prone to overfitting on a particular subset of the data.\n",
        "     - `scoring='f1_macro'` which means the measure to evaluate the models is the macro F1 score. F1 score is particularly useful when dealing with datasets that exhibit class imbalance as it balances the precision and recall.\n",
        "     - `n_jobs=-1` which allows using all available computer cores for parallel processing, speeding up the search.\n",
        "\n",
        "3. **Fitting the Grid Search Model:**\n",
        "   - `grid_search.fit(X_train, y_data)` is called to perform grid search. This means the model and its parameters will be trained and evaluated using the combinations from `param_grid` using the training data (`X_train` and `y_train`).\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "This code is a comprehensive setup for optimizing a logistic regression model, anticipating the best parameters for regularization strength, penalty type, and solver algorithm based on their effect on the macro F1 score. Such parameter tuning is crucial for achieving the best possible model performance, especially in scenarios where default parameters may not be sufficient.\n",
        "\n",
        "### Python Code Enhancement\n",
        "\n",
        "For enhancing the code's clarity, ensure that the logistic regression model (`log_reg`) is defined properly before use and that the data (`X_train`, `y_train`) are correctly processed and ready for model fitting. Here is a refined snippet assuming you've already loaded and prepared your data and imported necessary libraries:\n",
        "\n",
        "```python\n",
        "from sklearn.modelaptcha import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    log_reg,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the grid search model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "```\n",
        "\n",
        "This additional print statement helps you directly see which parameters were chosen as the best after the grid search."
      ],
      "metadata": {
        "id": "3wUF0HJRKRFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message4=ask_gpt_a_coding_question(gpt4turbo, '''\n",
        "I want to replace the logistic regression model here with a svm model. which parameters should I use in the gridsearchcv?\n",
        "change the code accordingly and elaborate on it\n",
        "# Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    log_reg,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "''')"
      ],
      "metadata": {
        "id": "-g-yqboCKMKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(message4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04bkpGMWMP30",
        "outputId": "acd2d04f-ef5c-41b5-abeb-15dc93316f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To replace the logistic regression model with a Support Vector Machine (SVM) model and utilize `GridSearchCV` for parameter tuning, we need to adjust several components:\n",
            "\n",
            "1. **SVM Model Selection**: Use SVM classifiers available in Scikit-learn (`SVC` class).\n",
            "2. **Parameter Grid**: Define a relevant set of parameters for SVM.\n",
            "3. **GridSearchCV Configuration**: Embed the SVM classifier and parameter grid into the `GridSearchCV`.\n",
            "\n",
            "### SVM Model\n",
            "`SVC` (Support Vector Classifier) will be used, which is suitable for binary classification tasks.\n",
            "\n",
            "### Parameters for GridSearchCV\n",
            "For an SVM model using `SVC`, key hyperparameters include:\n",
            "- `C`: Regularization parameter. The strength of the regularization is inversely proportional to C. It helps to avoid overfitting by penalizing the loss function.\n",
            "- `kernel`: Specifies the kernel type to be used in the algorithm. It can be 'linear', 'poly', 'rbf', etc.\n",
            "- `gamma`: Kernel coefficient for 'rbf', 'poly', and 'sigmoid'.\n",
            "  - If `gamma='scale'` (default), it uses `1 / (n_features * X.var())` as the value of gamma.\n",
            "  - If `gamma='auto'`, it uses `1/n_features`.\n",
            "\n",
            "### Proposed Grid for SVM\n",
            "A sensible approach will involve iterating over various values of `C`, different kernels, and, for some kernels like 'rbf' and 'poly', different values of `gamma`. A simple grid might look like this:\n",
            "```python\n",
            "param_grid = {\n",
            "    'C': [0.1, 1, 10],\n",
            "    'kernel': ['linear', 'rbf'],\n",
            "    'gamma': ['scale', 'auto']\n",
            "}\n",
            "```\n",
            "This grid explores linear and RBF kernels, two scaling approaches for `gamma`, and three values of `C`. The grid can be expanded based on computational resources and specific dataset characteristics.\n",
            "\n",
            "### Implementing in GridSearchCV\n",
            "Here is an updated Python code snippet incorporating an SVM model into `GridSearchCV`:\n",
            "\n",
            "```python\n",
            "from sklearn.svm import SVC\n",
            "from sklearn.model_selection import GridSearchCV\n",
            "\n",
            "# Define the model to use\n",
            "svm_model = SVC()\n",
            "\n",
            "# Define parameter grid specifically for SVM\n",
            "param_grid = {\n",
            "    'C': [0.1, 1, 10],\n",
            "    'kernel': ['linear', 'rbf'],\n",
            "    'gamma': ['scale', 'auto']\n",
            "}\n",
            "\n",
            "# Initialize GridSearchCV\n",
            "grid_search = GridSearchCV(\n",
            "    svm_model, \n",
            "    param_grid, \n",
            "    cv=3, \n",
            "    scoring='f1_macro', \n",
            "    n_jobs=-1\n",
            ")\n",
            "```\n",
            "\n",
            "This setup uses `SVC` with three-fold cross-validation and optimizes for the macro average of F1-score (`f1_macro`) over the parameter grid. It uses all available CPU cores (`n_jobs=-1`) to expedite processing. The choice of kernel, `C`, and `gamma` can be further tailored according to specific needs or preliminary results from iterative testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To replace the logistic regression model with a Support Vector Machine (SVM) model and utilize `GridSearchCV` for parameter tuning, we need to adjust several components:\n",
        "\n",
        "1. **SVM Model Selection**: Use SVM classifiers available in Scikit-learn (`SVC` class).\n",
        "2. **Parameter Grid**: Define a relevant set of parameters for SVM.\n",
        "3. **GridSearchCV Configuration**: Embed the SVM classifier and parameter grid into the `GridSearchCV`.\n",
        "\n",
        "### SVM Model\n",
        "`SVC` (Support Vector Classifier) will be used, which is suitable for binary classification tasks.\n",
        "\n",
        "### Parameters for GridSearchCV\n",
        "For an SVM model using `SVC`, key hyperparameters include:\n",
        "- `C`: Regularization parameter. The strength of the regularization is inversely proportional to C. It helps to avoid overfitting by penalizing the loss function.\n",
        "- `kernel`: Specifies the kernel type to be used in the algorithm. It can be 'linear', 'poly', 'rbf', etc.\n",
        "- `gamma`: Kernel coefficient for 'rbf', 'poly', and 'sigmoid'.\n",
        "  - If `gamma='scale'` (default), it uses `1 / (n_features * X.var())` as the value of gamma.\n",
        "  - If `gamma='auto'`, it uses `1/n_features`.\n",
        "\n",
        "### Proposed Grid for SVM\n",
        "A sensible approach will involve iterating over various values of `C`, different kernels, and, for some kernels like 'rbf' and 'poly', different values of `gamma`. A simple grid might look like this:\n",
        "```python\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "```\n",
        "This grid explores linear and RBF kernels, two scaling approaches for `gamma`, and three values of `C`. The grid can be expanded based on computational resources and specific dataset characteristics.\n",
        "\n",
        "### Implementing in GridSearchCV\n",
        "Here is an updated Python code snippet incorporating an SVM model into `GridSearchCV`:\n",
        "\n",
        "```python\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model to use\n",
        "svm_model = SVC()\n",
        "\n",
        "# Define parameter grid specifically for SVM\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    svm_model,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1\n",
        ")\n",
        "```\n",
        "\n",
        "This setup uses `SVC` with three-fold cross-validation and optimizes for the macro average of F1-score (`f1_macro`) over the parameter grid. It uses all available CPU cores (`n_jobs=-1`) to expedite processing. The choice of kernel, `C`, and `gamma` can be further tailored according to specific needs or preliminary results from iterative testing."
      ],
      "metadata": {
        "id": "HUQBYX1jMS_K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VRBdV4OuMSFu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
